{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n# Measure LLAMA speed\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import pandas\nimport matplotlib.pyplot as plt\nimport itertools\nimport torch\nfrom onnxrt_backend_dev.ext_test_case import unit_test_going\nfrom onnxrt_backend_dev.bench_run import run_benchmark, get_machine, BenchmarkError\n\nrepeat = 5\nscript_name = \"onnxrt_backend_dev.llama.dort_bench\"\nmachine = {} if unit_test_going() else get_machine()\n\nif machine.get(\"capability\", (0, 0)) >= (7, 0):\n    configs = []\n    for backend, device, num_hidden_layers in itertools.product(\n        [\"inductor\", \"ort\"],\n        [\"cpu\", \"cuda\"] if torch.cuda.is_available() else [\"cpu\"],\n        [1, 2],\n    ):\n        configs.append(\n            dict(\n                backend=backend,\n                device=device,\n                num_hidden_layers=num_hidden_layers,\n                repeat=repeat,\n            )\n        )\nelse:\n    configs = [\n        dict(backend=\"ort\", device=\"cpu\", num_hidden_layers=1, repeat=repeat),\n        dict(backend=\"ort\", device=\"cpu\", num_hidden_layers=2, repeat=repeat),\n    ]\n\n\ntry:\n    data = run_benchmark(script_name, configs, verbose=1)\n    data_collected = True\nexcept BenchmarkError as e:\n    print(e)\n    data_collected = False\n\nif data_collected:\n    df = pandas.DataFrame(data)\n    df = df.drop([\"ERROR\", \"OUTPUT\"], axis=1)\n    filename = \"plot_llama_bench.csv\"\n    df.to_csv(filename, index=False)\n    df = pandas.read_csv(filename)  # to cast type\n    print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "More simple\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "if data_collected:\n    try:\n        dfs = df[[\"backend\", \"num_hidden_layers\", \"time\", \"device\", \"warmup_time\"]]\n    except KeyError as e:\n        raise RuntimeError(f\"Missing columns in {df.columns}\\n{df.head().T}\") from e\n    print(dfs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plot.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "if data_collected:\n    fig, ax = plt.subplots(2, 2, figsize=(10, 6))\n\n    piv = dfs[dfs.device == \"cpu\"].pivot(\n        index=\"num_hidden_layers\", columns=\"backend\", values=\"warmup_time\"\n    )\n    if len(piv) > 0:\n        piv.plot(title=\"llama with dort on cpu\\nwarmup time\", ax=ax[0, 0])\n\n    piv = dfs[dfs.device == \"cuda\"].pivot(\n        index=\"num_hidden_layers\", columns=\"backend\", values=\"warmup_time\"\n    )\n    if len(piv) > 0:\n        piv.plot(title=\"llama with dort on cuda\\nwarmup time\", ax=ax[0, 1])\n\n    piv = dfs[dfs.device == \"cpu\"].pivot(\n        index=\"num_hidden_layers\", columns=\"backend\", values=\"time\"\n    )\n    if len(piv) > 0:\n        piv.plot(\n            title=f\"llama with dort on cpu\\ntraining time for {repeat} iterations\",\n            ax=ax[1, 0],\n        )\n\n    piv = dfs[dfs.device == \"cuda\"].pivot(\n        index=\"num_hidden_layers\", columns=\"backend\", values=\"time\"\n    )\n    if len(piv) > 0:\n        piv.plot(\n            title=f\"llama with dort on cuda\\ntraining time for {repeat} iterations\",\n            ax=ax[1, 1],\n        )\n\n    fig.tight_layout()\n    fig.savefig(\"plot_llama_bench.png\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}